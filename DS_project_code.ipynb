{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/usp787/DS_5110_Final_Project_LoRA/blob/Code/DS_project_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from datasets import load_dataset\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "iRw49Jo0RQ4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_goemotions_data():\n",
        "    \"\"\"Load GoEmotions dataset with pre-split train/val/test\"\"\"\n",
        "    print(\"\\nLoading GoEmotions dataset...\")\n",
        "    dataset = load_dataset('google-research-datasets/go_emotions', 'simplified')\n",
        "\n",
        "    print(f\"Train samples: {len(dataset['train']):,}\")\n",
        "    print(f\"Validation samples: {len(dataset['validation']):,}\")\n",
        "    print(f\"Test samples: {len(dataset['test']):,}\")\n",
        "\n",
        "    return dataset['train'], dataset['validation'], dataset['test']"
      ],
      "metadata": {
        "id": "SjyMOmaCSw3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_batch(batch_data, tokenizer, max_length=128):\n",
        "    \"\"\"\n",
        "    Convert raw text batch to model inputs\n",
        "    More flexible than Dataset class - easy to modify tokenization\n",
        "    \"\"\"\n",
        "    texts = [item['text'] for item in batch_data]\n",
        "\n",
        "    # Tokenize\n",
        "    encoding = tokenizer(\n",
        "        texts,\n",
        "        max_length=max_length,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    # Multi-label: Convert to binary vectors\n",
        "    labels = torch.zeros(len(batch_data), 28)\n",
        "    for i, item in enumerate(batch_data):\n",
        "        for label_id in item['labels']:\n",
        "            labels[i, label_id] = 1\n",
        "\n",
        "    return encoding['input_ids'], encoding['attention_mask'], labels"
      ],
      "metadata": {
        "id": "uVmoVjHgS5Gm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataloaders(train_data, val_data, test_data, tokenizer, batch_size=32, max_length=128):\n",
        "    \"\"\"\n",
        "    Create dataloaders from raw data\n",
        "    Using simple Dataset wrapper for DataLoader compatibility\n",
        "    \"\"\"\n",
        "    class SimpleDataset(Dataset):\n",
        "        def __init__(self, data):\n",
        "            self.data = data\n",
        "        def __len__(self):\n",
        "            return len(self.data)\n",
        "        def __getitem__(self, idx):\n",
        "            return self.data[idx]\n",
        "\n",
        "    # Wrap in Dataset for DataLoader\n",
        "    train_dataset = SimpleDataset(train_data)\n",
        "    val_dataset = SimpleDataset(val_data)\n",
        "    test_dataset = SimpleDataset(test_data)\n",
        "\n",
        "    # Custom collate function\n",
        "    def collate_fn(batch):\n",
        "        input_ids, attention_mask, labels = prepare_batch(batch, tokenizer, max_length)\n",
        "        return {\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask,\n",
        "            'labels': labels\n",
        "        }\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=collate_fn)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=collate_fn)\n",
        "\n",
        "    return train_loader, val_loader, test_loader"
      ],
      "metadata": {
        "id": "CYeK8GEcTAqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(num_labels=28, dropout=0.1, freeze_backbone=True):\n",
        "\n",
        "    # Load pre-trained DistilRoBERTa\n",
        "    backbone = AutoModel.from_pretrained('distilroberta-base')\n",
        "    hidden_size = backbone.config.hidden_size  # 768\n",
        "\n",
        "    # Optionally freeze backbone\n",
        "    if freeze_backbone:\n",
        "        for param in backbone.parameters():\n",
        "            param.requires_grad = False\n",
        "        print(\"✓ Backbone FROZEN (no fine-tuning)\")\n",
        "    else:\n",
        "        print(\"✓ Backbone UNFROZEN (will fine-tune)\")\n",
        "\n",
        "    # Build classifier head\n",
        "    classifier = nn.Sequential(\n",
        "        nn.Dropout(dropout),\n",
        "        nn.Linear(hidden_size, hidden_size // 2),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(dropout),\n",
        "        nn.Linear(hidden_size // 2, num_labels)\n",
        "    )\n",
        "\n",
        "    # Wrap in simple module\n",
        "    class EmotionClassifier(nn.Module):\n",
        "        def __init__(self, backbone, classifier):\n",
        "            super().__init__()\n",
        "            self.backbone = backbone\n",
        "            self.classifier = classifier\n",
        "\n",
        "        def forward(self, input_ids, attention_mask):\n",
        "            # Get embeddings\n",
        "            if self.backbone.training:\n",
        "                outputs = self.backbone(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            else:\n",
        "                with torch.no_grad():\n",
        "                    outputs = self.backbone(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "            # Use [CLS] token\n",
        "            pooled = outputs.last_hidden_state[:, 0, :]\n",
        "            logits = self.classifier(pooled)\n",
        "            return logits\n",
        "\n",
        "    model = EmotionClassifier(backbone, classifier)\n",
        "\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(f\"Total params: {total_params:,}\")\n",
        "    print(f\"Trainable params: {trainable_params:,} ({100*trainable_params/total_params:.2f}%)\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "1p5vAf_CTB6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(predictions, labels, threshold=0.5):\n",
        "\n",
        "    # Binarize predictions\n",
        "    pred_binary = (predictions >= threshold).astype(int)\n",
        "    labels = labels.astype(int)\n",
        "\n",
        "    # MICRO metrics: Global aggregation\n",
        "    micro_f1 = f1_score(labels, pred_binary, average='micro', zero_division=0)\n",
        "    micro_precision = precision_score(labels, pred_binary, average='micro', zero_division=0)\n",
        "    micro_recall = recall_score(labels, pred_binary, average='micro', zero_division=0)\n",
        "\n",
        "    # MACRO metrics: Per-class average\n",
        "    macro_f1 = f1_score(labels, pred_binary, average='macro', zero_division=0)\n",
        "    macro_precision = precision_score(labels, pred_binary, average='macro', zero_division=0)\n",
        "    macro_recall = recall_score(labels, pred_binary, average='macro', zero_division=0)\n",
        "\n",
        "    # Additional metrics\n",
        "    subset_acc = accuracy_score(labels, pred_binary)  # Exact match\n",
        "    hamming = np.mean(labels != pred_binary)  # Label-wise error\n",
        "\n",
        "    return {\n",
        "        'micro_f1': micro_f1,\n",
        "        'micro_precision': micro_precision,\n",
        "        'micro_recall': micro_recall,\n",
        "        'macro_f1': macro_f1,\n",
        "        'macro_precision': macro_precision,\n",
        "        'macro_recall': macro_recall,\n",
        "        'subset_accuracy': subset_acc,\n",
        "        'hamming_loss': hamming\n",
        "    }\n",
        "\n",
        "\n",
        "def print_metrics(metrics, prefix=\"\"):\n",
        "    \"\"\"Pretty print metrics\"\"\"\n",
        "    print(f\"\\n{prefix}Metrics:\")\n",
        "    print(f\"  Micro-F1: {metrics['micro_f1']:.4f} (weighted by frequency)\")\n",
        "    print(f\"  Macro-F1: {metrics['macro_f1']:.4f} (equal weight per class)\")\n",
        "    print(f\"  Micro-Precision: {metrics['micro_precision']:.4f}\")\n",
        "    print(f\"  Micro-Recall: {metrics['micro_recall']:.4f}\")\n",
        "    print(f\"  Macro-Precision: {metrics['macro_precision']:.4f}\")\n",
        "    print(f\"  Macro-Recall: {metrics['macro_recall']:.4f}\")\n",
        "    print(f\"  Subset Accuracy: {metrics['subset_accuracy']:.4f}\")\n",
        "    print(f\"  Hamming Loss: {metrics['hamming_loss']:.4f}\")"
      ],
      "metadata": {
        "id": "lDSwoA0MTfc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, dataloader, optimizer, criterion, device):\n",
        "    \"\"\"\n",
        "    Train for one epoch\n",
        "    Separate function - easy to modify training logic\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    progress_bar = tqdm(dataloader, desc=\"Training\")\n",
        "    for batch in progress_bar:\n",
        "        # Move to device\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        # Forward\n",
        "        logits = model(input_ids, attention_mask)\n",
        "        loss = criterion(logits, labels)\n",
        "\n",
        "        # Backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Track loss\n",
        "        total_loss += loss.item()\n",
        "        progress_bar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    return avg_loss"
      ],
      "metadata": {
        "id": "flP9vesWTmXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, dataloader, criterion, device):\n",
        "    \"\"\"\n",
        "    Evaluate model on a dataset\n",
        "    Returns loss + all metrics\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
        "            # Move to device\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            # Forward\n",
        "            logits = model(input_ids, attention_mask)\n",
        "            loss = criterion(logits, labels)\n",
        "\n",
        "            # Get predictions (sigmoid for multi-label)\n",
        "            probs = torch.sigmoid(logits)\n",
        "\n",
        "            # Collect\n",
        "            all_predictions.append(probs.cpu().numpy())\n",
        "            all_labels.append(labels.cpu().numpy())\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    # Aggregate\n",
        "    predictions = np.vstack(all_predictions)\n",
        "    labels = np.vstack(all_labels)\n",
        "\n",
        "    # Compute metrics\n",
        "    metrics = compute_metrics(predictions, labels)\n",
        "    metrics['loss'] = total_loss / len(dataloader)\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "s20V8oUaTpeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, device, epochs=5, lr=1e-3):\n",
        "    \"\"\"\n",
        "    Main training loop\n",
        "    Easy to modify hyperparameters and logic\n",
        "    \"\"\"\n",
        "    # Setup\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    optimizer = torch.optim.Adam(\n",
        "        filter(lambda p: p.requires_grad, model.parameters()),\n",
        "        lr=lr\n",
        "    )\n",
        "\n",
        "    best_val_macro_f1 = 0\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"Training Loop\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        # Train\n",
        "        train_loss = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
        "        print(f\"Train Loss: {train_loss:.4f}\")\n",
        "\n",
        "        # Validate\n",
        "        val_metrics = evaluate_model(model, val_loader, criterion, device)\n",
        "        print(f\"Val Loss: {val_metrics['loss']:.4f}\")\n",
        "        print_metrics(val_metrics, prefix=\"Validation \")\n",
        "\n",
        "        # Save best model\n",
        "        if val_metrics['macro_f1'] > best_val_macro_f1:\n",
        "            best_val_macro_f1 = val_metrics['macro_f1']\n",
        "            torch.save(model.state_dict(), 'best_baseline_model.pt')\n",
        "            print(f\"  ✓ New best model saved! (Macro-F1: {best_val_macro_f1:.4f})\")\n",
        "\n",
        "    return best_val_macro_f1"
      ],
      "metadata": {
        "id": "tw1e71G6TtW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    \"\"\"\n",
        "    Main execution function\n",
        "    Each step is separate - easy to run/modify individually\n",
        "    \"\"\"\n",
        "    # Config\n",
        "    BATCH_SIZE = 32\n",
        "    MAX_LENGTH = 128\n",
        "    EPOCHS = 5\n",
        "    LR = 1e-3\n",
        "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"DistilRoBERTa Baseline (NO Fine-tuning)\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Device: {DEVICE}\\n\")\n",
        "\n",
        "    # Step 1: Load data\n",
        "    train_data, val_data, test_data = load_goemotions_data()\n",
        "\n",
        "    # Step 2: Load tokenizer\n",
        "    print(\"\\nLoading tokenizer...\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained('distilroberta-base')\n",
        "\n",
        "    # Step 3: Create dataloaders\n",
        "    print(\"\\nCreating dataloaders...\")\n",
        "    train_loader, val_loader, test_loader = create_dataloaders(\n",
        "        train_data, val_data, test_data, tokenizer,\n",
        "        batch_size=BATCH_SIZE, max_length=MAX_LENGTH\n",
        "    )\n",
        "\n",
        "    # Step 4: Build model\n",
        "    print(\"\\nBuilding model...\")\n",
        "    model = build_model(num_labels=28, dropout=0.1, freeze_backbone=True)\n",
        "    model = model.to(DEVICE)\n",
        "\n",
        "    # Step 5: Train\n",
        "    best_macro_f1 = train_model(\n",
        "        model, train_loader, val_loader, DEVICE,\n",
        "        epochs=EPOCHS, lr=LR\n",
        "    )\n",
        "\n",
        "    # Step 6: Final test evaluation\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"Final Test Evaluation (Unseen Data)\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    model.load_state_dict(torch.load('best_baseline_model.pt'))\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    test_metrics = evaluate_model(model, test_loader, criterion, DEVICE)\n",
        "\n",
        "    print_metrics(test_metrics, prefix=\"Test \")\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"Baseline Complete!\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"\\nKey Results:\")\n",
        "    print(f\"  Best Val Macro-F1: {best_macro_f1:.4f}\")\n",
        "    print(f\"  Test Macro-F1: {test_metrics['macro_f1']:.4f}\")\n",
        "    print(f\"  Test Micro-F1: {test_metrics['micro_f1']:.4f}\")\n",
        "    print(f\"\\nReady for LoRA comparison!\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ls-6pgHNU8ks",
        "outputId": "9566fa58-d6ff-4bfa-dc5f-47ebfdde1daf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "DistilRoBERTa Baseline (NO Fine-tuning)\n",
            "============================================================\n",
            "Device: cuda\n",
            "\n",
            "\n",
            "Loading GoEmotions dataset...\n",
            "Train samples: 43,410\n",
            "Validation samples: 5,426\n",
            "Test samples: 5,427\n",
            "\n",
            "Loading tokenizer...\n",
            "\n",
            "Creating dataloaders...\n",
            "\n",
            "Building model...\n",
            "✓ Backbone FROZEN (no fine-tuning)\n",
            "Total params: 82,424,476\n",
            "Trainable params: 306,076 (0.37%)\n",
            "\n",
            "============================================================\n",
            "Training Loop\n",
            "============================================================\n",
            "\n",
            "Epoch 1/5\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1357/1357 [02:11<00:00, 10.30it/s, loss=0.1268]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 170/170 [00:15<00:00, 11.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.1238\n",
            "\n",
            "Validation Metrics:\n",
            "  Micro-F1: 0.2029 (weighted by frequency)\n",
            "  Macro-F1: 0.0389 (equal weight per class)\n",
            "  Micro-Precision: 0.6632\n",
            "  Micro-Recall: 0.1197\n",
            "  Macro-Precision: 0.1381\n",
            "  Macro-Recall: 0.0261\n",
            "  Subset Accuracy: 0.1231\n",
            "  Hamming Loss: 0.0395\n",
            "  ✓ New best model saved! (Macro-F1: 0.0389)\n",
            "\n",
            "Epoch 2/5\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1357/1357 [02:20<00:00,  9.64it/s, loss=0.1132]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 170/170 [00:16<00:00, 10.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.1163\n",
            "\n",
            "Validation Metrics:\n",
            "  Micro-F1: 0.2670 (weighted by frequency)\n",
            "  Macro-F1: 0.0940 (equal weight per class)\n",
            "  Micro-Precision: 0.6619\n",
            "  Micro-Recall: 0.1672\n",
            "  Macro-Precision: 0.2452\n",
            "  Macro-Recall: 0.0736\n",
            "  Subset Accuracy: 0.1587\n",
            "  Hamming Loss: 0.0386\n",
            "  ✓ New best model saved! (Macro-F1: 0.0940)\n",
            "\n",
            "Epoch 3/5\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1357/1357 [02:24<00:00,  9.39it/s, loss=0.0720]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1179\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 170/170 [00:16<00:00, 10.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.1121\n",
            "\n",
            "Validation Metrics:\n",
            "  Micro-F1: 0.2648 (weighted by frequency)\n",
            "  Macro-F1: 0.0979 (equal weight per class)\n",
            "  Micro-Precision: 0.7020\n",
            "  Micro-Recall: 0.1632\n",
            "  Macro-Precision: 0.2710\n",
            "  Macro-Recall: 0.0709\n",
            "  Subset Accuracy: 0.1600\n",
            "  Hamming Loss: 0.0381\n",
            "  ✓ New best model saved! (Macro-F1: 0.0979)\n",
            "\n",
            "Epoch 4/5\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1357/1357 [02:25<00:00,  9.33it/s, loss=0.0838]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1159\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 170/170 [00:16<00:00, 10.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.1094\n",
            "\n",
            "Validation Metrics:\n",
            "  Micro-F1: 0.3158 (weighted by frequency)\n",
            "  Macro-F1: 0.1011 (equal weight per class)\n",
            "  Micro-Precision: 0.6857\n",
            "  Micro-Recall: 0.2052\n",
            "  Macro-Precision: 0.2584\n",
            "  Macro-Recall: 0.0738\n",
            "  Subset Accuracy: 0.2035\n",
            "  Hamming Loss: 0.0373\n",
            "  ✓ New best model saved! (Macro-F1: 0.1011)\n",
            "\n",
            "Epoch 5/5\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1357/1357 [02:26<00:00,  9.29it/s, loss=0.1102]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1147\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 170/170 [00:16<00:00, 10.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.1082\n",
            "\n",
            "Validation Metrics:\n",
            "  Micro-F1: 0.3317 (weighted by frequency)\n",
            "  Macro-F1: 0.1200 (equal weight per class)\n",
            "  Micro-Precision: 0.6778\n",
            "  Micro-Recall: 0.2196\n",
            "  Macro-Precision: 0.3495\n",
            "  Macro-Recall: 0.0900\n",
            "  Subset Accuracy: 0.2147\n",
            "  Hamming Loss: 0.0372\n",
            "  ✓ New best model saved! (Macro-F1: 0.1200)\n",
            "\n",
            "============================================================\n",
            "Final Test Evaluation (Unseen Data)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 170/170 [00:16<00:00, 10.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Metrics:\n",
            "  Micro-F1: 0.3394 (weighted by frequency)\n",
            "  Macro-F1: 0.1245 (equal weight per class)\n",
            "  Micro-Precision: 0.6980\n",
            "  Micro-Recall: 0.2242\n",
            "  Macro-Precision: 0.3186\n",
            "  Macro-Recall: 0.0943\n",
            "  Subset Accuracy: 0.2171\n",
            "  Hamming Loss: 0.0364\n",
            "\n",
            "============================================================\n",
            "Baseline Complete!\n",
            "============================================================\n",
            "\n",
            "Key Results:\n",
            "  Best Val Macro-F1: 0.1200\n",
            "  Test Macro-F1: 0.1245\n",
            "  Test Micro-F1: 0.3394\n",
            "\n",
            "Ready for LoRA comparison!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}