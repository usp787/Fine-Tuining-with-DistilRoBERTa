{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/usp787/DS_5110_Final_Project_LoRA/blob/Code/LoRA_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from datasets import load_dataset\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "iRw49Jo0RQ4j"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_goemotions_data():\n",
        "    \"\"\"Load GoEmotions dataset with pre-split train/val/test\"\"\"\n",
        "    print(\"\\nLoading GoEmotions dataset...\")\n",
        "    dataset = load_dataset('google-research-datasets/go_emotions', 'simplified')\n",
        "\n",
        "    print(f\"Train samples: {len(dataset['train']):,}\")\n",
        "    print(f\"Validation samples: {len(dataset['validation']):,}\")\n",
        "    print(f\"Test samples: {len(dataset['test']):,}\")\n",
        "\n",
        "    return dataset['train'], dataset['validation'], dataset['test']"
      ],
      "metadata": {
        "id": "SjyMOmaCSw3X"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_batch(batch_data, tokenizer, max_length=128):\n",
        "    \"\"\"\n",
        "    Convert raw text batch to model inputs\n",
        "    More flexible than Dataset class - easy to modify tokenization\n",
        "    \"\"\"\n",
        "    texts = [item['text'] for item in batch_data]\n",
        "\n",
        "    # Tokenize\n",
        "    encoding = tokenizer(\n",
        "        texts,\n",
        "        max_length=max_length,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    # Multi-label: Convert to binary vectors\n",
        "    labels = torch.zeros(len(batch_data), 28)\n",
        "    for i, item in enumerate(batch_data):\n",
        "        for label_id in item['labels']:\n",
        "            labels[i, label_id] = 1\n",
        "\n",
        "    return encoding['input_ids'], encoding['attention_mask'], labels"
      ],
      "metadata": {
        "id": "uVmoVjHgS5Gm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataloaders(train_data, val_data, test_data, tokenizer, batch_size=32, max_length=128):\n",
        "    \"\"\"\n",
        "    Create dataloaders from raw data\n",
        "    Using simple Dataset wrapper for DataLoader compatibility\n",
        "    \"\"\"\n",
        "    class SimpleDataset(Dataset):\n",
        "        def __init__(self, data):\n",
        "            self.data = data\n",
        "        def __len__(self):\n",
        "            return len(self.data)\n",
        "        def __getitem__(self, idx):\n",
        "            return self.data[idx]\n",
        "\n",
        "    # Wrap in Dataset for DataLoader\n",
        "    train_dataset = SimpleDataset(train_data)\n",
        "    val_dataset = SimpleDataset(val_data)\n",
        "    test_dataset = SimpleDataset(test_data)\n",
        "\n",
        "    # Custom collate function\n",
        "    def collate_fn(batch):\n",
        "        input_ids, attention_mask, labels = prepare_batch(batch, tokenizer, max_length)\n",
        "        return {\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask,\n",
        "            'labels': labels\n",
        "        }\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=collate_fn)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=collate_fn)\n",
        "\n",
        "    return train_loader, val_loader, test_loader"
      ],
      "metadata": {
        "id": "CYeK8GEcTAqx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import peft librareis(Hugging Face) for LoRA\n",
        "from peft import LoraConfig, get_peft_model, TaskType"
      ],
      "metadata": {
        "id": "d_1vf04G6a66"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(num_labels=28, dropout=0.1, rank=16):\n",
        "    \"\"\"\n",
        "    Build DistilRoBERTa with LoRA adapters.\n",
        "    \"\"\"\n",
        "    # 1. Load the pre-trained backbone (Standard AutoModel)\n",
        "    # This is currently FROZEN (all weights)\n",
        "    backbone = AutoModel.from_pretrained('distilroberta-base')\n",
        "\n",
        "    # 2. Configure LoRA\n",
        "    # We target the attention mechanism linear layers.\n",
        "    # DistilRoBERTa uses 'key', 'query', 'value' in its attention modules.\n",
        "    peft_config = LoraConfig(\n",
        "        task_type=TaskType.FEATURE_EXTRACTION, # We are using it as a feature extractor for our head\n",
        "        r=rank,                  # The dimension of the low-rank matrices (8, 16, 64)\n",
        "        lora_alpha=32,           # Scaling factor (usually 2x rank)\n",
        "        lora_dropout=0.1,        # Regularization\n",
        "        target_modules=['key', 'query', 'value'] # Specific to RoBERTa-style models\n",
        "    )\n",
        "\n",
        "    # 3. Inject Adapters (The Magic Step)\n",
        "    # This makes the backbone's adapters TRAINABLE, while keeping the rest frozen.\n",
        "    backbone = get_peft_model(backbone, peft_config)\n",
        "    print(\"\\n✓ LoRA Adapters injected into Backbone\")\n",
        "    backbone.print_trainable_parameters() # Helpful built-in print function\n",
        "\n",
        "    # 4. Define the Classifier Head (Same as before)\n",
        "    # The backbone now returns adapted embeddings!\n",
        "    class EmotionClassifier(nn.Module):\n",
        "        def __init__(self, backbone, classifier):\n",
        "            super().__init__()\n",
        "            self.backbone = backbone\n",
        "            self.classifier = classifier\n",
        "\n",
        "        def forward(self, input_ids, attention_mask):\n",
        "            # The backbone handles the LoRA logic internally\n",
        "            outputs = self.backbone(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "            # Use [CLS] token representation\n",
        "            pooled = outputs.last_hidden_state[:, 0, :]\n",
        "            logits = self.classifier(pooled)\n",
        "            return logits\n",
        "\n",
        "    # Re-create your classifier head\n",
        "    hidden_size = backbone.config.hidden_size\n",
        "    classifier_head = nn.Sequential(\n",
        "        nn.Dropout(dropout),\n",
        "        nn.Linear(hidden_size, hidden_size // 2),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(dropout),\n",
        "        nn.Linear(hidden_size // 2, num_labels)\n",
        "    )\n",
        "\n",
        "    # Combine them\n",
        "    model = EmotionClassifier(backbone, classifier_head)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "1p5vAf_CTB6u"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(predictions, labels, threshold=0.5):\n",
        "\n",
        "    # Binarize predictions\n",
        "    pred_binary = (predictions >= threshold).astype(int)\n",
        "    labels = labels.astype(int)\n",
        "\n",
        "    # MICRO metrics: Global aggregation\n",
        "    micro_f1 = f1_score(labels, pred_binary, average='micro', zero_division=0)\n",
        "    micro_precision = precision_score(labels, pred_binary, average='micro', zero_division=0)\n",
        "    micro_recall = recall_score(labels, pred_binary, average='micro', zero_division=0)\n",
        "\n",
        "    # MACRO metrics: Per-class average\n",
        "    macro_f1 = f1_score(labels, pred_binary, average='macro', zero_division=0)\n",
        "    macro_precision = precision_score(labels, pred_binary, average='macro', zero_division=0)\n",
        "    macro_recall = recall_score(labels, pred_binary, average='macro', zero_division=0)\n",
        "\n",
        "    # Additional metrics\n",
        "    subset_acc = accuracy_score(labels, pred_binary)  # Exact match\n",
        "    hamming = np.mean(labels != pred_binary)  # Label-wise error\n",
        "\n",
        "    return {\n",
        "        'micro_f1': micro_f1,\n",
        "        'micro_precision': micro_precision,\n",
        "        'micro_recall': micro_recall,\n",
        "        'macro_f1': macro_f1,\n",
        "        'macro_precision': macro_precision,\n",
        "        'macro_recall': macro_recall,\n",
        "        'subset_accuracy': subset_acc,\n",
        "        'hamming_loss': hamming\n",
        "    }\n",
        "\n",
        "\n",
        "def print_metrics(metrics, prefix=\"\"):\n",
        "    \"\"\"Pretty print metrics\"\"\"\n",
        "    print(f\"\\n{prefix}Metrics:\")\n",
        "    print(f\"  Micro-F1: {metrics['micro_f1']:.4f} (weighted by frequency)\")\n",
        "    print(f\"  Macro-F1: {metrics['macro_f1']:.4f} (equal weight per class)\")\n",
        "    print(f\"  Micro-Precision: {metrics['micro_precision']:.4f}\")\n",
        "    print(f\"  Micro-Recall: {metrics['micro_recall']:.4f}\")\n",
        "    print(f\"  Macro-Precision: {metrics['macro_precision']:.4f}\")\n",
        "    print(f\"  Macro-Recall: {metrics['macro_recall']:.4f}\")\n",
        "    print(f\"  Subset Accuracy: {metrics['subset_accuracy']:.4f}\")\n",
        "    print(f\"  Hamming Loss: {metrics['hamming_loss']:.4f}\")"
      ],
      "metadata": {
        "id": "lDSwoA0MTfc0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, dataloader, optimizer, criterion, device):\n",
        "    \"\"\"\n",
        "    Train for one epoch\n",
        "    Separate function - easy to modify training logic\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    progress_bar = tqdm(dataloader, desc=\"Training\")\n",
        "    for batch in progress_bar:\n",
        "        # Move to device\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        # Forward\n",
        "        logits = model(input_ids, attention_mask)\n",
        "        loss = criterion(logits, labels)\n",
        "\n",
        "        # Backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Track loss\n",
        "        total_loss += loss.item()\n",
        "        progress_bar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    return avg_loss"
      ],
      "metadata": {
        "id": "flP9vesWTmXj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, dataloader, criterion, device):\n",
        "    \"\"\"\n",
        "    Evaluate model on a dataset\n",
        "    Returns loss + all metrics\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
        "            # Move to device\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            # Forward\n",
        "            logits = model(input_ids, attention_mask)\n",
        "            loss = criterion(logits, labels)\n",
        "\n",
        "            # Get predictions (sigmoid for multi-label)\n",
        "            probs = torch.sigmoid(logits)\n",
        "\n",
        "            # Collect\n",
        "            all_predictions.append(probs.cpu().numpy())\n",
        "            all_labels.append(labels.cpu().numpy())\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    # Aggregate\n",
        "    predictions = np.vstack(all_predictions)\n",
        "    labels = np.vstack(all_labels)\n",
        "\n",
        "    # Compute metrics\n",
        "    metrics = compute_metrics(predictions, labels)\n",
        "    metrics['loss'] = total_loss / len(dataloader)\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "s20V8oUaTpeP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, device, epochs=5, lr=1e-3):\n",
        "    \"\"\"\n",
        "    Main training loop\n",
        "    Easy to modify hyperparameters and logic\n",
        "    \"\"\"\n",
        "    # Setup\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    optimizer = torch.optim.Adam(\n",
        "        filter(lambda p: p.requires_grad, model.parameters()),\n",
        "        lr=lr\n",
        "    )\n",
        "\n",
        "    best_val_macro_f1 = 0\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"Training Loop\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        # Train\n",
        "        train_loss = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
        "        print(f\"Train Loss: {train_loss:.4f}\")\n",
        "\n",
        "        # Validate\n",
        "        val_metrics = evaluate_model(model, val_loader, criterion, device)\n",
        "        print(f\"Val Loss: {val_metrics['loss']:.4f}\")\n",
        "        print_metrics(val_metrics, prefix=\"Validation \")\n",
        "\n",
        "        # Save best model\n",
        "        if val_metrics['macro_f1'] > best_val_macro_f1:\n",
        "            best_val_macro_f1 = val_metrics['macro_f1']\n",
        "            torch.save(model.state_dict(), 'best_LoRA_model.pt')\n",
        "            print(f\"  ✓ New best model saved! (Macro-F1: {best_val_macro_f1:.4f})\")\n",
        "\n",
        "    return best_val_macro_f1"
      ],
      "metadata": {
        "id": "tw1e71G6TtW6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    \"\"\"\n",
        "    Main execution function\n",
        "    Each step is separate - easy to run/modify individually\n",
        "    \"\"\"\n",
        "    # Config\n",
        "    BATCH_SIZE = 32\n",
        "    MAX_LENGTH = 128\n",
        "    EPOCHS = 5\n",
        "    LR = 1e-3\n",
        "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"DistilRoBERTa LoRA\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Device: {DEVICE}\\n\")\n",
        "\n",
        "    # Step 1: Load data\n",
        "    train_data, val_data, test_data = load_goemotions_data()\n",
        "\n",
        "    # Step 2: Load tokenizer\n",
        "    print(\"\\nLoading tokenizer...\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained('distilroberta-base')\n",
        "\n",
        "    # Step 3: Create dataloaders\n",
        "    print(\"\\nCreating dataloaders...\")\n",
        "    train_loader, val_loader, test_loader = create_dataloaders(\n",
        "        train_data, val_data, test_data, tokenizer,\n",
        "        batch_size=BATCH_SIZE, max_length=MAX_LENGTH\n",
        "    )\n",
        "\n",
        "    # Step 4: Build model\n",
        "    print(\"\\nBuilding model...\")\n",
        "    model = build_model(num_labels=28, dropout=0.1)\n",
        "    model = model.to(DEVICE)\n",
        "\n",
        "    # Step 5: Train\n",
        "    best_macro_f1 = train_model(\n",
        "        model, train_loader, val_loader, DEVICE,\n",
        "        epochs=EPOCHS, lr=LR\n",
        "    )\n",
        "\n",
        "    # Step 6: Final test evaluation\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"Final Test Evaluation (Unseen Data)\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    model.load_state_dict(torch.load('best_LoRA_model.pt'))\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    test_metrics = evaluate_model(model, test_loader, criterion, DEVICE)\n",
        "\n",
        "    print_metrics(test_metrics, prefix=\"Test \")\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"LoRA Complete!\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"\\nKey Results:\")\n",
        "    print(f\"  Best Val Macro-F1: {best_macro_f1:.4f}\")\n",
        "    print(f\"  Test Macro-F1: {test_metrics['macro_f1']:.4f}\")\n",
        "    print(f\"  Test Micro-F1: {test_metrics['micro_f1']:.4f}\")\n",
        "    print(f\"\\nReady for LoRA comparison!\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a5fb183dc95440b59b0bc52ede325f86",
            "0e01300724c4469d9c54b831288e81fc",
            "2b29af2290894ff7849d7beb861ec7d9",
            "8e24db1e577442e7a503187a2c106f1a",
            "fb9b09bf5b7844319bb1231741f06781",
            "ff6e10e853fb4e87a495648008853d7d",
            "8589f7b0072a44b990dea0a0193f0326",
            "1b1cacff85884580b383c75434be2fea",
            "37a636af722547a6b6c927a08554a6ae",
            "be0b1f58dcbf4c0b9549015a1999a6d2",
            "393de9316e9244ac9de230adcaa8b9b1"
          ]
        },
        "id": "Ls-6pgHNU8ks",
        "outputId": "b552e19f-1bd0-4c10-e1c4-0d036517f564"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "DistilRoBERTa LoRA\n",
            "============================================================\n",
            "Device: cuda\n",
            "\n",
            "\n",
            "Loading GoEmotions dataset...\n",
            "Train samples: 43,410\n",
            "Validation samples: 5,426\n",
            "Test samples: 5,427\n",
            "\n",
            "Loading tokenizer...\n",
            "\n",
            "Creating dataloaders...\n",
            "\n",
            "Building model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/331M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a5fb183dc95440b59b0bc52ede325f86"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ LoRA Adapters injected into Backbone\n",
            "trainable params: 442,368 || all params: 82,560,768 || trainable%: 0.5358\n",
            "\n",
            "============================================================\n",
            "Training Loop\n",
            "============================================================\n",
            "\n",
            "Epoch 1/5\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1357/1357 [05:04<00:00,  4.46it/s, loss=0.1041]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1209\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 170/170 [00:17<00:00,  9.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.0970\n",
            "\n",
            "Validation Metrics:\n",
            "  Micro-F1: 0.4865 (weighted by frequency)\n",
            "  Macro-F1: 0.2817 (equal weight per class)\n",
            "  Micro-Precision: 0.7112\n",
            "  Micro-Recall: 0.3697\n",
            "  Macro-Precision: 0.5197\n",
            "  Macro-Recall: 0.2465\n",
            "  Subset Accuracy: 0.3546\n",
            "  Hamming Loss: 0.0328\n",
            "  ✓ New best model saved! (Macro-F1: 0.2817)\n",
            "\n",
            "Epoch 2/5\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1357/1357 [05:03<00:00,  4.46it/s, loss=0.0835]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0996\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 170/170 [00:17<00:00,  9.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.0942\n",
            "\n",
            "Validation Metrics:\n",
            "  Micro-F1: 0.5169 (weighted by frequency)\n",
            "  Macro-F1: 0.3414 (equal weight per class)\n",
            "  Micro-Precision: 0.7085\n",
            "  Micro-Recall: 0.4069\n",
            "  Macro-Precision: 0.5020\n",
            "  Macro-Recall: 0.2916\n",
            "  Subset Accuracy: 0.3892\n",
            "  Hamming Loss: 0.0319\n",
            "  ✓ New best model saved! (Macro-F1: 0.3414)\n",
            "\n",
            "Epoch 3/5\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1357/1357 [05:04<00:00,  4.46it/s, loss=0.0877]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 170/170 [00:17<00:00,  9.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.0924\n",
            "\n",
            "Validation Metrics:\n",
            "  Micro-F1: 0.5273 (weighted by frequency)\n",
            "  Macro-F1: 0.3766 (equal weight per class)\n",
            "  Micro-Precision: 0.6981\n",
            "  Micro-Recall: 0.4237\n",
            "  Macro-Precision: 0.6039\n",
            "  Macro-Recall: 0.3131\n",
            "  Subset Accuracy: 0.4029\n",
            "  Hamming Loss: 0.0319\n",
            "  ✓ New best model saved! (Macro-F1: 0.3766)\n",
            "\n",
            "Epoch 4/5\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1357/1357 [05:04<00:00,  4.46it/s, loss=0.0811]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0961\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 170/170 [00:17<00:00,  9.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.0931\n",
            "\n",
            "Validation Metrics:\n",
            "  Micro-F1: 0.5179 (weighted by frequency)\n",
            "  Macro-F1: 0.3646 (equal weight per class)\n",
            "  Micro-Precision: 0.7051\n",
            "  Micro-Recall: 0.4092\n",
            "  Macro-Precision: 0.6266\n",
            "  Macro-Recall: 0.3031\n",
            "  Subset Accuracy: 0.3957\n",
            "  Hamming Loss: 0.0320\n",
            "\n",
            "Epoch 5/5\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1357/1357 [05:03<00:00,  4.46it/s, loss=0.0890]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 170/170 [00:17<00:00,  9.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.1022\n",
            "\n",
            "Validation Metrics:\n",
            "  Micro-F1: 0.4861 (weighted by frequency)\n",
            "  Macro-F1: 0.3015 (equal weight per class)\n",
            "  Micro-Precision: 0.6716\n",
            "  Micro-Recall: 0.3809\n",
            "  Macro-Precision: 0.5270\n",
            "  Macro-Recall: 0.2570\n",
            "  Subset Accuracy: 0.3658\n",
            "  Hamming Loss: 0.0338\n",
            "\n",
            "============================================================\n",
            "Final Test Evaluation (Unseen Data)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 170/170 [00:17<00:00,  9.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Metrics:\n",
            "  Micro-F1: 0.5223 (weighted by frequency)\n",
            "  Macro-F1: 0.3811 (equal weight per class)\n",
            "  Micro-Precision: 0.6908\n",
            "  Micro-Recall: 0.4198\n",
            "  Macro-Precision: 0.6155\n",
            "  Macro-Recall: 0.3166\n",
            "  Subset Accuracy: 0.3978\n",
            "  Hamming Loss: 0.0320\n",
            "\n",
            "============================================================\n",
            "LoRA Complete!\n",
            "============================================================\n",
            "\n",
            "Key Results:\n",
            "  Best Val Macro-F1: 0.3766\n",
            "  Test Macro-F1: 0.3811\n",
            "  Test Micro-F1: 0.5223\n",
            "\n",
            "Ready for LoRA comparison!\n"
          ]
        }
      ]
    }
  ]
}
